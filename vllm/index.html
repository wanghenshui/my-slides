<!doctype html>

<html>
<head>

    <title>vLLM介绍</title>

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>reveal.js</title>

    <link rel="stylesheet" href="../reveal.js/dist/reset.css">
    <link rel="stylesheet" href="../reveal.js/dist/reveal.css">
    <link rel="stylesheet" href="../assets/white.css" id="theme">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="../reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
    <div class="reveal">
        <div class="slides">
            <section data-markdown>
                <textarea data-template>
                    # vLLM
                    - 背景/动机
                    - 架构/设计
  			    </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    <!-- .element: style="font-size:80%;" -->
                    <h1 style="text-align: left;">背景</h1>
                    - llm推理需求显著，相关服务众多但效率低下
                    - 需要一个快速且方便使用/定制的llm推理服务

                    ```python
                    from vllm import LLM

                    # Example prompts.
                    prompts = ["Hello, my name is", "The capital of France is"]
                    # Create an LLM with HF model name.
                    llm = LLM(model="meta-llama/Meta-Llama-3.1-8B")
                    # Generate texts from the prompts. 
                    outputs = llm.generate(prompts) # also llm.chat(messages)]
                    ```
                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    <!-- .element: style="font-size:80%;" -->
                    <h3 style="text-align: left;">vllm接口</h2>
                    <h4 style="text-align: left;">server</h3>

                    ```shell
                    vllm serve meta-llama/Meta-Llama-3.1-8B
                    ```

                    <h3 style="text-align: left;">client</h3>

                    ```shell
                    curl http://localhost:8000/v1/completions \
                    -H "Content-Type: application/json" \
                    -d '{
                        "model": "meta-llama/Meta-Llama-3.1-8B",
                        "prompt": "San Francisco is a",
                        "max_tokens": 7,
                        "temperature": 0
                    }'

                    ```

                </textarea>
            </section>

            <section data-markdown>
                <textarea data-template>
                    <!-- .element: style="font-size:75%;" -->
                    <h1 style="text-align: left;">整体框架</h1>

                    ![](./vllm1.png) <!-- .element height="80%" width="80%" -->
                    
                    即便从V0演化到了分离式架构V1 组件还是这些
                </textarea>
            </section>

            <section>
                <div class="mermaid">
                    <pre>
                    flowchart TD
                    subgraph "EngineCore初始化<br>engine/core.py"
                        INIT_ENGINE["EngineCore.__init__()<br>引擎初始化"]
                        INIT_EXECUTOR["初始化Executor<br>executor_class.__init__()"]
                        AVAIL_MEM["determine_available_memory()<br>确定可用显存"]
                        GET_KV_CONFIG["get_kv_cache_config()<br>获取KV缓存配置"]
                        INIT_KV["initialize_from_config()<br>初始化KV缓存"]
                        INIT_SCHED["初始化Scheduler<br>Scheduler()"]
                    end
                    
                    subgraph "Executor初始化<br>执行者初始化"
                        MP_INIT["MultiprocExecutor._init_executor()<br>多进程执行者初始化"]
                        CREATE_MQ["创建消息队列<br>rpc_broadcast_mq"]
                        CREATE_WORKERS["创建Worker进程<br>make_worker_process()"]
                        WORKER_INIT["Worker进程初始化<br>worker_main()"]
                        INIT_DEVICE["初始化设备<br>init_device()"]
                        LOAD_MODEL["加载模型<br>load_model()"]
                    end
                    
                    subgraph "Worker KV缓存<br>worker/gpu_model_runner.py"
                        GPU_RUNNER["GPUModelRunner.__init__()<br>GPU模型运行器初始化"]
                        ALLOC_KV["分配KV缓存Tensor<br>每层2个(K/V)"]
                        KV_SHAPE["KV缓存形状<br>(2, num_blocks, block_size, kv_head, head_size)"]
                    end
                    
                    INIT_ENGINE --> INIT_EXECUTOR
                    INIT_ENGINE --> AVAIL_MEM
                    AVAIL_MEM --> GET_KV_CONFIG
                    GET_KV_CONFIG --> INIT_KV
                    INIT_KV --> INIT_SCHED
                    
                    INIT_EXECUTOR --> MP_INIT
                    MP_INIT --> CREATE_MQ
                    MP_INIT --> CREATE_WORKERS
                    CREATE_WORKERS --> WORKER_INIT
                    WORKER_INIT --> INIT_DEVICE
                    WORKER_INIT --> LOAD_MODEL
                    
                    LOAD_MODEL --> GPU_RUNNER
                    GPU_RUNNER --> ALLOC_KV
                    ALLOC_KV --> KV_SHAPE
                </pre>
                  </div>
            </section>
            <section>
                <section data-markdown>
                    <textarea data-template>
                        ## Q/A
                    </textarea>
                </section>

                <section data-markdown>
                    <textarea data-template>
                        ## 参考资料 {.left}

                        - https://github.com/vllm-project/vllm
                    </textarea>
                </section>
            </section>
        </div>
    </div>


    <script src="../reveal.js/dist/reveal.js"></script>
    <script src="../reveal.js/plugin/notes/notes.js"></script>
    <script src="../reveal.js/plugin/markdown/markdown.js"></script>
    <script src="../reveal.js/plugin/highlight/highlight.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js-mermaid-plugin@11.4.1/plugin/mermaid/mermaid.js"></script>
    <script>
        // More info about initialization & config:
        // - https://revealjs.com/initialization/
        // - https://revealjs.com/config/
        Reveal.initialize({
            hash: true,
            // PowerPoint 宽屏尺寸 (16:9)
            width: 1280,
            height: 720,
            
            // PowerPoint 标准尺寸 (4:3)
            // width: 1024, 
            // height: 768,
            
            // 控制内容缩放
            margin: 0.1,
            
            // 其他常用配置
            controls: true,
            progress: true,
            center: true,
            hash: true,
            scrollable: true,
            mermaid: {
            // flowchart: {
            //   curve: 'linear',
            // },
            },

            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMermaid]
        });
    </script>
</body>

</html>
